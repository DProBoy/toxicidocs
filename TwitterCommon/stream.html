<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>TwitterCommon.stream API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TwitterCommon.stream</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import shutil
import json
from flatten_json import flatten
from .errors import *
import os


# data is a pandas dataframe
_DATA_FOLDER = &#39;./data/&#39;


def does_db_exist():
    return os.path.isfile(_DATA_FOLDER+&#34;stream_db.json&#34;)


def does_stream_exist(stream_name):
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        return stream_name in data


def stream_db_push_operation(stream_name, procedure, params):
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        data.setdefault(stream_name, {&#34;operations&#34;: [], &#34;size&#34;: 0})
        data[stream_name][&#34;operations&#34;].append({procedure: params})
        json.dump(data, db)


def stream_db_new_data(stream_name):
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        data[stream_name][&#34;size&#34;] += 1
        json.dump(data, db)


def stream_db_get(stream_name):
    &#34;&#34;&#34;
        TODO (this function supposes stream already in db)
    &#34;&#34;&#34;
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        return data[stream_name]


class Stream:
    &#34;&#34;&#34;
       a Stream object is a centralized entity that points and operates on a specific piece of data.

       The data it points to may either be initialized from a csv file, a json file
       or it might be initialized as empty. Moreover, it can listen in to updates (new
       pieces of data) and reapply previous transformations that have already been applied,
       onto that piece of information.

       Note:
           All streams need to have a name, so they can be registered in the StreamDB and persist
           after the application closes.

           Streams must either be initialized from_csv, from_json or have from_listener = True (for an initially empty streal)

       Args:
           name (str): name of the stream. If this is a test stream that will be deleted after, the name needs to start with &#34;test&#34;
           from_csv (:obj:`str`, optional): name of a csv file from which the stream might be initialized
           from_json (:obj:`str`, optional): name of a json file from which the stream might be initialized (JSON is a much slower read than)
           from_listener (:obj:`bool`, optional): if the stream will be initialized from listener
           preprocessing (:obj:&#39;Callable[[pd.DataFrame], pd.DataFrame], optional): list of preprocessing functions (operations) to apply to data
           encoding (:obj:&#39;str&#39;, optional): encoding to use when reading csv/json file
           low_memory (:obj:&#39;bool&#39;, optional): whether or not to limit memory usage when working with csv files using Pandas
           flatten_json (:obj:&#39;bool&#39;, optional): whether or not to flatten json if reading a json file

       Attributes:
           name (str): name of the stream. If this is a test stream that will be deleted after, the name needs to start with &#34;test&#34;
           preprocessing (:obj:&#39;Callable[[pd.DataFrame], pd.DataFrame], optional): list of preprocessing functions (operations) to apply to data
           low_memory (:obj:&#39;bool&#39;, optional): whether or not to limit memory usage when working with csv files using Pandas

       &#34;&#34;&#34;

    def __init__(self, name, from_csv=None, from_json=None, from_listener=False, preprocessing=None, encoding=&#34;utf-8&#34;, low_memory=True, flatten_json=True):
        self.name = name
        self.preprocessing = preprocessing
        self.low_memory = low_memory

        # if does_stream_exist(self.name):
        #     pass

        if from_csv:
            shutil.copyfile(from_csv, &#34;data/&#34;+name+&#34;_stream.csv&#34;)
        elif from_json:
            with open(from_json, encoding=encoding) as file:
                data = json.load(file)
                # json must be flattened before transforming it into a data frame
                if flatten_json:
                    data = [flatten(data_elem) for data_elem in data]
                df = pd.DataFrame(data)
                df.to_csv(&#34;data/&#34;+name+&#34;_stream.csv&#34;)
        elif not from_listener:
            raise StreamSourceNotExist()
        if not from_listener:
            if preprocessing:
                for f in preprocessing:
                    df = pd.read_csv(
                        &#34;data/&#34;+name+&#34;_stream.csv&#34;, index_col=0)
                    df = f(df)
                    df.to_csv(&#34;data/&#34;+name+&#34;_stream.csv&#34;)

    def get_dataframe(self, start_row=None, num_rows=None, col_names=None):
        &#34;&#34;&#34;used to get a dataframe of our data

        Args:
            start_row (:obj:&#39;int&#39;, optional): number of row to start reading from.
            num_row (:obj:&#39;int&#39;, optional): number of rows to read starting from start_row.
            col_names (:obj:&#39;[str]&#39;, optional): list of names of columns to read.

        Returns:
            pd.Dataframe: the read dataframe.

        &#34;&#34;&#34;
        df = pd.read_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                         skiprows=start_row, nrows=num_rows, usecols=col_names, index_col=0)
        return df

    def get_json(self, start_row=None, num_rows=None, col_names=None):
        &#34;&#34;&#34;used to get a json representation of our data

        Args:
            start_row (:obj:&#39;int&#39;, optional): number of row to start reading from.
            num_row (:obj:&#39;int&#39;, optional): number of rows to read starting from start_row.
            col_names (:obj:&#39;[str]&#39;, optional): list of names of columns to read.

        Returns:
            str: json representation of the read data.

        &#34;&#34;&#34;
        df = self.get_dataframe(
            start=start_row, num_rows=num_rows, col_names=col_names)
        result = df.to_json(orient=&#34;split&#34;)
        parsed = json.loads(result)
        return json.dumps(parsed, indent=4)

    def listen(self, stream_listener):
        &#34;&#34;&#34;used to connect a Stream Listener with our Stream

        Args:
            stream_listener (TwitterCollect.stream_listener.StreamListener): stream listener to connect with this stream

        &#34;&#34;&#34;
        self.listener = stream_listener
        stream_listener.set_stream(self)
        stream_listener.filter()
        pass

    # TODO : Consider batch preprocessing for better performance
    def new_data(self, data):
        &#34;&#34;&#34;called by the stream listener to add a new piece of data to the stream

        Args:
            data (dict): new piece of data

        &#34;&#34;&#34;
        data = pd.DataFrame(data)
        if self.preprocessing:
            for f in self.preprocessing:
                data = f(data)
        if os.path.isfile(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;) and os.stat(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;).st_size != 0:
            data.to_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                        mode=&#34;a&#34;, header=False)
        else:
            data.to_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                        mode=&#34;a&#34;, header=True)
        # if does_stream_exist(self.name):
        #     stream_db_new_data(self.name)

    # TODO : a more advanced error logger

    def handle_error(errors):
        print(errors)
        pass

    def apply(processing):
        pass

    def filter(filters):
        pass

    def close_listener(self):
        &#34;&#34;&#34;
            Function used to disconnect from the stream listener
            Note: 
                This function is to be called by the stream listener
        &#34;&#34;&#34;
        self.listener.set_stream(None)
        self.listener = None
        pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="TwitterCommon.stream.does_db_exist"><code class="name flex">
<span>def <span class="ident">does_db_exist</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def does_db_exist():
    return os.path.isfile(_DATA_FOLDER+&#34;stream_db.json&#34;)</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.does_stream_exist"><code class="name flex">
<span>def <span class="ident">does_stream_exist</span></span>(<span>stream_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def does_stream_exist(stream_name):
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        return stream_name in data</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.stream_db_get"><code class="name flex">
<span>def <span class="ident">stream_db_get</span></span>(<span>stream_name)</span>
</code></dt>
<dd>
<div class="desc"><p>TODO (this function supposes stream already in db)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stream_db_get(stream_name):
    &#34;&#34;&#34;
        TODO (this function supposes stream already in db)
    &#34;&#34;&#34;
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        return data[stream_name]</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.stream_db_new_data"><code class="name flex">
<span>def <span class="ident">stream_db_new_data</span></span>(<span>stream_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stream_db_new_data(stream_name):
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        data[stream_name][&#34;size&#34;] += 1
        json.dump(data, db)</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.stream_db_push_operation"><code class="name flex">
<span>def <span class="ident">stream_db_push_operation</span></span>(<span>stream_name, procedure, params)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stream_db_push_operation(stream_name, procedure, params):
    with open(_DATA_FOLDER+&#34;stream_db.json&#34;, &#34;w&#34;) as db:
        data = json.load(db)
        data.setdefault(stream_name, {&#34;operations&#34;: [], &#34;size&#34;: 0})
        data[stream_name][&#34;operations&#34;].append({procedure: params})
        json.dump(data, db)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="TwitterCommon.stream.Stream"><code class="flex name class">
<span>class <span class="ident">Stream</span></span>
<span>(</span><span>name, from_csv=None, from_json=None, from_listener=False, preprocessing=None, encoding='utf-8', low_memory=True, flatten_json=True)</span>
</code></dt>
<dd>
<div class="desc"><p>a Stream object is a centralized entity that points and operates on a specific piece of data.</p>
<p>The data it points to may either be initialized from a csv file, a json file
or it might be initialized as empty. Moreover, it can listen in to updates (new
pieces of data) and reapply previous transformations that have already been applied,
onto that piece of information.</p>
<h2 id="note">Note</h2>
<p>All streams need to have a name, so they can be registered in the StreamDB and persist
after the application closes.</p>
<p>Streams must either be initialized from_csv, from_json or have from_listener = True (for an initially empty streal)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>name of the stream. If this is a test stream that will be deleted after, the name needs to start with "test"</dd>
</dl>
<p>from_csv (:obj:<code>str</code>, optional): name of a csv file from which the stream might be initialized
from_json (:obj:<code>str</code>, optional): name of a json file from which the stream might be initialized (JSON is a much slower read than)
from_listener (:obj:<code>bool</code>, optional): if the stream will be initialized from listener
preprocessing (:obj:'Callable[[pd.DataFrame], pd.DataFrame], optional): list of preprocessing functions (operations) to apply to data
encoding (:obj:'str', optional): encoding to use when reading csv/json file
low_memory (:obj:'bool', optional): whether or not to limit memory usage when working with csv files using Pandas
flatten_json (:obj:'bool', optional): whether or not to flatten json if reading a json file</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>name of the stream. If this is a test stream that will be deleted after, the name needs to start with "test"</dd>
</dl>
<p>preprocessing (:obj:'Callable[[pd.DataFrame], pd.DataFrame], optional): list of preprocessing functions (operations) to apply to data
low_memory (:obj:'bool', optional): whether or not to limit memory usage when working with csv files using Pandas</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Stream:
    &#34;&#34;&#34;
       a Stream object is a centralized entity that points and operates on a specific piece of data.

       The data it points to may either be initialized from a csv file, a json file
       or it might be initialized as empty. Moreover, it can listen in to updates (new
       pieces of data) and reapply previous transformations that have already been applied,
       onto that piece of information.

       Note:
           All streams need to have a name, so they can be registered in the StreamDB and persist
           after the application closes.

           Streams must either be initialized from_csv, from_json or have from_listener = True (for an initially empty streal)

       Args:
           name (str): name of the stream. If this is a test stream that will be deleted after, the name needs to start with &#34;test&#34;
           from_csv (:obj:`str`, optional): name of a csv file from which the stream might be initialized
           from_json (:obj:`str`, optional): name of a json file from which the stream might be initialized (JSON is a much slower read than)
           from_listener (:obj:`bool`, optional): if the stream will be initialized from listener
           preprocessing (:obj:&#39;Callable[[pd.DataFrame], pd.DataFrame], optional): list of preprocessing functions (operations) to apply to data
           encoding (:obj:&#39;str&#39;, optional): encoding to use when reading csv/json file
           low_memory (:obj:&#39;bool&#39;, optional): whether or not to limit memory usage when working with csv files using Pandas
           flatten_json (:obj:&#39;bool&#39;, optional): whether or not to flatten json if reading a json file

       Attributes:
           name (str): name of the stream. If this is a test stream that will be deleted after, the name needs to start with &#34;test&#34;
           preprocessing (:obj:&#39;Callable[[pd.DataFrame], pd.DataFrame], optional): list of preprocessing functions (operations) to apply to data
           low_memory (:obj:&#39;bool&#39;, optional): whether or not to limit memory usage when working with csv files using Pandas

       &#34;&#34;&#34;

    def __init__(self, name, from_csv=None, from_json=None, from_listener=False, preprocessing=None, encoding=&#34;utf-8&#34;, low_memory=True, flatten_json=True):
        self.name = name
        self.preprocessing = preprocessing
        self.low_memory = low_memory

        # if does_stream_exist(self.name):
        #     pass

        if from_csv:
            shutil.copyfile(from_csv, &#34;data/&#34;+name+&#34;_stream.csv&#34;)
        elif from_json:
            with open(from_json, encoding=encoding) as file:
                data = json.load(file)
                # json must be flattened before transforming it into a data frame
                if flatten_json:
                    data = [flatten(data_elem) for data_elem in data]
                df = pd.DataFrame(data)
                df.to_csv(&#34;data/&#34;+name+&#34;_stream.csv&#34;)
        elif not from_listener:
            raise StreamSourceNotExist()
        if not from_listener:
            if preprocessing:
                for f in preprocessing:
                    df = pd.read_csv(
                        &#34;data/&#34;+name+&#34;_stream.csv&#34;, index_col=0)
                    df = f(df)
                    df.to_csv(&#34;data/&#34;+name+&#34;_stream.csv&#34;)

    def get_dataframe(self, start_row=None, num_rows=None, col_names=None):
        &#34;&#34;&#34;used to get a dataframe of our data

        Args:
            start_row (:obj:&#39;int&#39;, optional): number of row to start reading from.
            num_row (:obj:&#39;int&#39;, optional): number of rows to read starting from start_row.
            col_names (:obj:&#39;[str]&#39;, optional): list of names of columns to read.

        Returns:
            pd.Dataframe: the read dataframe.

        &#34;&#34;&#34;
        df = pd.read_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                         skiprows=start_row, nrows=num_rows, usecols=col_names, index_col=0)
        return df

    def get_json(self, start_row=None, num_rows=None, col_names=None):
        &#34;&#34;&#34;used to get a json representation of our data

        Args:
            start_row (:obj:&#39;int&#39;, optional): number of row to start reading from.
            num_row (:obj:&#39;int&#39;, optional): number of rows to read starting from start_row.
            col_names (:obj:&#39;[str]&#39;, optional): list of names of columns to read.

        Returns:
            str: json representation of the read data.

        &#34;&#34;&#34;
        df = self.get_dataframe(
            start=start_row, num_rows=num_rows, col_names=col_names)
        result = df.to_json(orient=&#34;split&#34;)
        parsed = json.loads(result)
        return json.dumps(parsed, indent=4)

    def listen(self, stream_listener):
        &#34;&#34;&#34;used to connect a Stream Listener with our Stream

        Args:
            stream_listener (TwitterCollect.stream_listener.StreamListener): stream listener to connect with this stream

        &#34;&#34;&#34;
        self.listener = stream_listener
        stream_listener.set_stream(self)
        stream_listener.filter()
        pass

    # TODO : Consider batch preprocessing for better performance
    def new_data(self, data):
        &#34;&#34;&#34;called by the stream listener to add a new piece of data to the stream

        Args:
            data (dict): new piece of data

        &#34;&#34;&#34;
        data = pd.DataFrame(data)
        if self.preprocessing:
            for f in self.preprocessing:
                data = f(data)
        if os.path.isfile(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;) and os.stat(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;).st_size != 0:
            data.to_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                        mode=&#34;a&#34;, header=False)
        else:
            data.to_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                        mode=&#34;a&#34;, header=True)
        # if does_stream_exist(self.name):
        #     stream_db_new_data(self.name)

    # TODO : a more advanced error logger

    def handle_error(errors):
        print(errors)
        pass

    def apply(processing):
        pass

    def filter(filters):
        pass

    def close_listener(self):
        &#34;&#34;&#34;
            Function used to disconnect from the stream listener
            Note: 
                This function is to be called by the stream listener
        &#34;&#34;&#34;
        self.listener.set_stream(None)
        self.listener = None
        pass</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="TwitterCommon.stream.Stream.apply"><code class="name flex">
<span>def <span class="ident">apply</span></span>(<span>processing)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply(processing):
    pass</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.Stream.close_listener"><code class="name flex">
<span>def <span class="ident">close_listener</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to disconnect from the stream listener
Note:
This function is to be called by the stream listener</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close_listener(self):
    &#34;&#34;&#34;
        Function used to disconnect from the stream listener
        Note: 
            This function is to be called by the stream listener
    &#34;&#34;&#34;
    self.listener.set_stream(None)
    self.listener = None
    pass</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.Stream.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>filters)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(filters):
    pass</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.Stream.get_dataframe"><code class="name flex">
<span>def <span class="ident">get_dataframe</span></span>(<span>self, start_row=None, num_rows=None, col_names=None)</span>
</code></dt>
<dd>
<div class="desc"><p>used to get a dataframe of our data</p>
<h2 id="args">Args</h2>
<p>start_row (:obj:'int', optional): number of row to start reading from.
num_row (:obj:'int', optional): number of rows to read starting from start_row.
col_names (:obj:'[str]', optional): list of names of columns to read.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.Dataframe</code></dt>
<dd>the read dataframe.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_dataframe(self, start_row=None, num_rows=None, col_names=None):
    &#34;&#34;&#34;used to get a dataframe of our data

    Args:
        start_row (:obj:&#39;int&#39;, optional): number of row to start reading from.
        num_row (:obj:&#39;int&#39;, optional): number of rows to read starting from start_row.
        col_names (:obj:&#39;[str]&#39;, optional): list of names of columns to read.

    Returns:
        pd.Dataframe: the read dataframe.

    &#34;&#34;&#34;
    df = pd.read_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                     skiprows=start_row, nrows=num_rows, usecols=col_names, index_col=0)
    return df</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.Stream.get_json"><code class="name flex">
<span>def <span class="ident">get_json</span></span>(<span>self, start_row=None, num_rows=None, col_names=None)</span>
</code></dt>
<dd>
<div class="desc"><p>used to get a json representation of our data</p>
<h2 id="args">Args</h2>
<p>start_row (:obj:'int', optional): number of row to start reading from.
num_row (:obj:'int', optional): number of rows to read starting from start_row.
col_names (:obj:'[str]', optional): list of names of columns to read.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>json representation of the read data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_json(self, start_row=None, num_rows=None, col_names=None):
    &#34;&#34;&#34;used to get a json representation of our data

    Args:
        start_row (:obj:&#39;int&#39;, optional): number of row to start reading from.
        num_row (:obj:&#39;int&#39;, optional): number of rows to read starting from start_row.
        col_names (:obj:&#39;[str]&#39;, optional): list of names of columns to read.

    Returns:
        str: json representation of the read data.

    &#34;&#34;&#34;
    df = self.get_dataframe(
        start=start_row, num_rows=num_rows, col_names=col_names)
    result = df.to_json(orient=&#34;split&#34;)
    parsed = json.loads(result)
    return json.dumps(parsed, indent=4)</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.Stream.handle_error"><code class="name flex">
<span>def <span class="ident">handle_error</span></span>(<span>errors)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def handle_error(errors):
    print(errors)
    pass</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.Stream.listen"><code class="name flex">
<span>def <span class="ident">listen</span></span>(<span>self, stream_listener)</span>
</code></dt>
<dd>
<div class="desc"><p>used to connect a Stream Listener with our Stream</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>stream_listener</code></strong> :&ensp;<code><a title="TwitterCollect.stream_listener.StreamListener" href="../TwitterCollect/stream_listener.html#TwitterCollect.stream_listener.StreamListener">StreamListener</a></code></dt>
<dd>stream listener to connect with this stream</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def listen(self, stream_listener):
    &#34;&#34;&#34;used to connect a Stream Listener with our Stream

    Args:
        stream_listener (TwitterCollect.stream_listener.StreamListener): stream listener to connect with this stream

    &#34;&#34;&#34;
    self.listener = stream_listener
    stream_listener.set_stream(self)
    stream_listener.filter()
    pass</code></pre>
</details>
</dd>
<dt id="TwitterCommon.stream.Stream.new_data"><code class="name flex">
<span>def <span class="ident">new_data</span></span>(<span>self, data)</span>
</code></dt>
<dd>
<div class="desc"><p>called by the stream listener to add a new piece of data to the stream</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code></dt>
<dd>new piece of data</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_data(self, data):
    &#34;&#34;&#34;called by the stream listener to add a new piece of data to the stream

    Args:
        data (dict): new piece of data

    &#34;&#34;&#34;
    data = pd.DataFrame(data)
    if self.preprocessing:
        for f in self.preprocessing:
            data = f(data)
    if os.path.isfile(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;) and os.stat(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;).st_size != 0:
        data.to_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                    mode=&#34;a&#34;, header=False)
    else:
        data.to_csv(&#34;data/&#34;+self.name+&#34;_stream.csv&#34;,
                    mode=&#34;a&#34;, header=True)
    # if does_stream_exist(self.name):
    #     stream_db_new_data(self.name)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="TwitterCommon" href="index.html">TwitterCommon</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="TwitterCommon.stream.does_db_exist" href="#TwitterCommon.stream.does_db_exist">does_db_exist</a></code></li>
<li><code><a title="TwitterCommon.stream.does_stream_exist" href="#TwitterCommon.stream.does_stream_exist">does_stream_exist</a></code></li>
<li><code><a title="TwitterCommon.stream.stream_db_get" href="#TwitterCommon.stream.stream_db_get">stream_db_get</a></code></li>
<li><code><a title="TwitterCommon.stream.stream_db_new_data" href="#TwitterCommon.stream.stream_db_new_data">stream_db_new_data</a></code></li>
<li><code><a title="TwitterCommon.stream.stream_db_push_operation" href="#TwitterCommon.stream.stream_db_push_operation">stream_db_push_operation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="TwitterCommon.stream.Stream" href="#TwitterCommon.stream.Stream">Stream</a></code></h4>
<ul class="two-column">
<li><code><a title="TwitterCommon.stream.Stream.apply" href="#TwitterCommon.stream.Stream.apply">apply</a></code></li>
<li><code><a title="TwitterCommon.stream.Stream.close_listener" href="#TwitterCommon.stream.Stream.close_listener">close_listener</a></code></li>
<li><code><a title="TwitterCommon.stream.Stream.filter" href="#TwitterCommon.stream.Stream.filter">filter</a></code></li>
<li><code><a title="TwitterCommon.stream.Stream.get_dataframe" href="#TwitterCommon.stream.Stream.get_dataframe">get_dataframe</a></code></li>
<li><code><a title="TwitterCommon.stream.Stream.get_json" href="#TwitterCommon.stream.Stream.get_json">get_json</a></code></li>
<li><code><a title="TwitterCommon.stream.Stream.handle_error" href="#TwitterCommon.stream.Stream.handle_error">handle_error</a></code></li>
<li><code><a title="TwitterCommon.stream.Stream.listen" href="#TwitterCommon.stream.Stream.listen">listen</a></code></li>
<li><code><a title="TwitterCommon.stream.Stream.new_data" href="#TwitterCommon.stream.Stream.new_data">new_data</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>